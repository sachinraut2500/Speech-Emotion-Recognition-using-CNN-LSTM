# -*- coding: utf-8 -*-
"""Speech Emotion Recognition using CNN + LSTM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pKYgrwW1BbCxeOcU-7lO2w31ebT7-_yO
"""

# speech_emotion_recognition.py

import os
import numpy as np
import librosa
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, LSTM, TimeDistributed
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical

def extract_features(file_path, max_pad_len=174):
    try:
        audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')
        mel_spec = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_mels=40)
        log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)
        if log_mel_spec.shape[1] < max_pad_len:
            pad_width = max_pad_len - log_mel_spec.shape[1]
            log_mel_spec = np.pad(log_mel_spec, pad_width=((0,0),(0,pad_width)), mode='constant')
        else:
            log_mel_spec = log_mel_spec[:, :max_pad_len]
        return log_mel_spec
    except Exception as e:
        print(f"Error encountered while parsing file: {file_path}")
        return None

def load_data(data_path):
    emotions = []
    features = []
    for dirname, _, filenames in os.walk(data_path):
        for filename in filenames:
            if filename.endswith('.wav'):
                file_path = os.path.join(dirname, filename)
                feature = extract_features(file_path)
                if feature is not None:
                    features.append(feature)
                    # Assuming emotion label is in folder name
                    emotion = os.path.basename(dirname)
                    emotions.append(emotion)
    return np.array(features), np.array(emotions)

def build_model(input_shape, num_classes):
    model = Sequential()
    model.add(Conv2D(32, (3,3), activation='relu', input_shape=input_shape))
    model.add(MaxPooling2D((2,2)))
    model.add(Dropout(0.3))

    model.add(Conv2D(64, (3,3), activation='relu'))
    model.add(MaxPooling2D((2,2)))
    model.add(Dropout(0.3))

    model.add(TimeDistributed(Flatten()))
    model.add(LSTM(64))
    model.add(Dense(64, activation='relu'))
    model.add(Dropout(0.3))
    model.add(Dense(num_classes, activation='softmax'))

    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

def main():
    DATA_PATH = 'data/'  # Your dataset folder organized by emotion subfolders
    print("Loading data...")
    X, y = load_data(DATA_PATH)
    X = X[..., np.newaxis]  # Add channel dimension

    print("Encoding labels...")
    le = LabelEncoder()
    y_enc = le.fit_transform(y)
    y_cat = to_categorical(y_enc)

    X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=42)

    input_shape = X_train.shape[1:]  # (40, 174, 1)
    num_classes = y_cat.shape[1]

    print("Building model...")
    model = build_model(input_shape, num_classes)
    print(model.summary())

    print("Training model...")
    model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))

if __name__ == "__main__":
    main()